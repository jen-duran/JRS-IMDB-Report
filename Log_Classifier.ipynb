{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os \n",
    "\n",
    "def create_bow():\n",
    "    directories = ['train/pos', 'train/neg', 'test/pos', 'test/neg'] \n",
    "\n",
    "    text = [] \n",
    "    score = [] \n",
    "    original_score = []\n",
    "\n",
    "    for directory in directories: \n",
    "        print(f'Current directory: {directory}') \n",
    "        train_contents = os.listdir(directory)\n",
    "\n",
    "        print(f'Total reviews in {directory}: {len(train_contents)}')\n",
    "        \n",
    "        for i in train_contents: \n",
    "            file_name = os.path.basename(i)\n",
    "            text_file_path = os.path.join(directory, i) \n",
    "            review_score = int(i[:len(i)-4].split('_')[1])\n",
    "\n",
    "            original_score.append(review_score) \n",
    "            \n",
    "            if review_score >= 7: \n",
    "                review_score = 1\n",
    "            elif review_score <= 4: \n",
    "                review_score = 0\n",
    "            else: \n",
    "                continue # don't consider reviews that are neutral rated  \n",
    "            \n",
    "            with open(text_file_path, 'r', encoding='utf-8') as f: \n",
    "                text_review = f.readline() \n",
    "\n",
    "                text.append(text_review)\n",
    "                score.append(review_score)\n",
    "        \n",
    "        print(f'Finished {directory}\\n') \n",
    "\n",
    "    vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,1)) \n",
    "    total_words = vectorizer.fit_transform(text) \n",
    "\n",
    "    print(f'Total data shape: {total_words.shape}')\n",
    "    print('Finished running.') \n",
    "    \n",
    "    return total_words, score, original_score, text\n",
    "\n",
    "X, y, score, text = create_bow() \n",
    "\n",
    "# X is total vectorized words, removing stop words and 1-gram \n",
    "# y is modified based on scores -> 1 and 0 \n",
    "# score is original scores\n",
    "# text is array of all reviews \n",
    "\n",
    "# TRAIN DATA : total 25_000 -> 12_500 pos and 12_500 neg\n",
    "# TEST DATA : total 25_000 -> 12_500 pos and 12_500 neg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Classifier\n",
    "\n",
    "# Uses test + train data and splits 25/75 split to create new train + test data set.\n",
    "\n",
    "def logistic_classifier(X, y): \n",
    "    seed = 42\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=seed) \n",
    "    \n",
    "    classifier = LogisticRegression(penalty='l1', solver='liblinear', fit_intercept=True)\n",
    "    classifier.fit(X_train, y_train) \n",
    "    \n",
    "    test_accuracy = classifier.score(X_test, y_test) \n",
    "    train_accuracy = classifier.score(X_train, y_train) \n",
    "    \n",
    "    print('\\nTesting accuracy:', format( 100*test_accuracy , '.2f') )\n",
    "    print('\\nTraining accuracy:', format( 100*train_accuracy , '.2f') )\n",
    "\n",
    "    return classifier\n",
    "\n",
    "logistic_classifier(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Accuracy vs Regularization of Logistic Classifier\n",
    "\n",
    "# evaluating test + train accuracy on different regularization strenghts\n",
    "seed = 42\n",
    "\n",
    "def accuracy_vs_regular(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=seed) \n",
    "\n",
    "    coefs = [] \n",
    "    train_acc = [] \n",
    "    test_acc = [] \n",
    "    cs = [0, 0.1, 1, 10, 50, 100, 1000] \n",
    "    \n",
    "    for c in cs: \n",
    "        if c == 0: \n",
    "            classifier = LogisticRegression(penalty=None, fit_intercept=True, max_iter=1000) \n",
    "        else: \n",
    "            classifier = LogisticRegression(penalty='l1', solver='liblinear', C=c, fit_intercept=True, max_iter=1000)\n",
    "            \n",
    "        classifier.fit(X_train, y_train) \n",
    "        \n",
    "        coefs.append(classifier.coef_)\n",
    "        \n",
    "        train_acc.append(classifier.score(X_train, y_train))\n",
    "        test_acc.append(classifier.score(X_test, y_test))\n",
    "        \n",
    "    fix, axes = plt.subplots() \n",
    "    \n",
    "    axes.semilogx(cs, train_acc, color='red', label='training accuracy')\n",
    "    axes.semilogx(cs, test_acc, color='blue', label='testing accuracy')\n",
    "\n",
    "    axes.set_xlabel('Regularization Strength', fontsize=13)\n",
    "    axes.set_ylabel('Accuracy', fontsize=13)\n",
    "    \n",
    "    axes.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    return train_acc, test_acc, coefs\n",
    "    \n",
    "train_acc, test_acc, coefs = accuracy_vs_regular(X, y)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
